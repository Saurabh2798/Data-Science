{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict, namedtuple, OrderedDict\n",
    "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution\n",
    "import os\n",
    "from io import BytesIO\n",
    "from itertools import chain\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence = namedtuple(\"Sentence\", \"words tags\")\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\"Read tagged sentence data\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        sentence_lines = [line.split(\"\\n\") for line in f.read().split(\"\\n\\n\")]\n",
    "    return OrderedDict(((s[0], Sentence(*zip(*[line.strip().split(\"\\t\")\n",
    "                        for line in s[1:]]))) for s in sentence_lines if s[0]))\n",
    "\n",
    "def read_tags(filename):\n",
    "    \"\"\"Read a list of word tag classes\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        tags = f.read().split(\"\\n\")\n",
    "    return frozenset(tags)\n",
    "\n",
    "class Subset(namedtuple(\"BaseSet\", \"sentences keys vocab X tagset Y N stream\")):\n",
    "    def __new__(cls, sentences, keys):\n",
    "        word_sequences = tuple([sentences[k].words for k in keys])\n",
    "        tag_sequences = tuple([sentences[k].tags for k in keys])\n",
    "        wordset = frozenset(chain(*word_sequences))\n",
    "        tagset = frozenset(chain(*tag_sequences))\n",
    "        N = sum(1 for _ in chain(*(sentences[k].words for k in keys)))\n",
    "        stream = tuple(zip(chain(*word_sequences), chain(*tag_sequences)))\n",
    "        return super().__new__(cls, {k: sentences[k] for k in keys}, keys, wordset, word_sequences,\n",
    "                               tagset, tag_sequences, N, stream.__iter__)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.sentences.items())\n",
    "\n",
    "\n",
    "class Dataset(namedtuple(\"_Dataset\", \"sentences keys vocab X tagset Y training_set testing_set N stream\")):\n",
    "    def __new__(cls, tagfile, datafile, train_test_split=0.8, seed=112890):\n",
    "        tagset = read_tags(tagfile)\n",
    "        sentences = read_data(datafile)\n",
    "        keys = tuple(sentences.keys())\n",
    "        wordset = frozenset(chain(*[s.words for s in sentences.values()]))\n",
    "        word_sequences = tuple([sentences[k].words for k in keys])\n",
    "        tag_sequences = tuple([sentences[k].tags for k in keys])\n",
    "        N = sum(1 for _ in chain(*(s.words for s in sentences.values())))\n",
    "        \n",
    "        # split data into train/test sets\n",
    "        _keys = list(keys)\n",
    "        if seed is not None: random.seed(seed)\n",
    "        random.shuffle(_keys)\n",
    "        split = int(train_test_split * len(_keys))\n",
    "        training_data = Subset(sentences, _keys[:split])\n",
    "        testing_data = Subset(sentences, _keys[split:])\n",
    "        stream = tuple(zip(chain(*word_sequences), chain(*tag_sequences)))\n",
    "        return super().__new__(cls, dict(sentences), keys, wordset, word_sequences, tagset,\n",
    "                               tag_sequences, training_data, testing_data, N, stream.__iter__)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.sentences.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57340 sentences in the corpus.\n",
      "Train: 45872, Test: 11468\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(\"tags_universal.txt\", \"brown-universal.txt\", train_test_split=0.8)\n",
    "\n",
    "print(f\"There are {len(data)} sentences in the corpus.\")\n",
    "print(f\"Train: {len(data.training_set)}, Test: {len(data.testing_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: b100-38532\n",
      "words: ('Perhaps', 'it', 'was', 'right', ';', ';')\n",
      "tags: ('ADV', 'PRON', 'VERB', 'ADJ', '.', '.')\n"
     ]
    }
   ],
   "source": [
    "key = 'b100-38532'\n",
    "print(f\"Sentence: {key}\")\n",
    "print(f\"words: {data.sentences[key].words}\")\n",
    "print(f\"tags: {data.sentences[key].tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 1161192, unique words: 56057\n",
      "Samples-Train: 928458, unique words: 50536\n",
      "Samples-Test: 232734, unique words: 25112\n"
     ]
    }
   ],
   "source": [
    "print(f\"Samples: {data.N}, unique words: {len(data.vocab)}\")\n",
    "print(f\"Samples-Train: {data.training_set.N}, unique words: {len(data.training_set.vocab)}\")\n",
    "print(f\"Samples-Test: {data.testing_set.N}, unique words: {len(data.testing_set.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 :  ('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.'):\n",
      "\n",
      "Labels 1 : ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.'):\n",
      "\n",
      "Sentence 2 :  ('But', 'there', 'seemed', 'to', 'be', 'some', 'difference', 'of', 'opinion', 'as', 'to', 'how', 'far', 'the', 'board', 'should', 'go', ',', 'and', 'whose', 'advice', 'it', 'should', 'follow', '.'):\n",
      "\n",
      "Labels 2 : ('CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADP', 'ADV', 'ADV', 'DET', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', '.'):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accessing words with Dataset.X and tags with Dataset.Y \n",
    "for i in range(2):    \n",
    "    print(f\"Sentence {i+1} :  {data.X[i]}:\\n\")\n",
    "    print(f\"Labels {i+1} : {data.Y[i]}:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mr.', 'NOUN')\n",
      "('Podger', 'NOUN')\n",
      "('had', 'VERB')\n",
      "('thanked', 'VERB')\n",
      "('him', 'PRON')\n"
     ]
    }
   ],
   "source": [
    "# (word, tag) stream\n",
    "for i, pair in enumerate(data.stream()):\n",
    "    print(pair)\n",
    "    if i > 3: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a MFC(Most Frequent Class) Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_counts(tags, words):\n",
    "    d = defaultdict(lambda: defaultdict(int))\n",
    "    for tag, word in zip(tags, words):\n",
    "        d[tag][word] += 1\n",
    "    return d\n",
    "\n",
    "tags = [tag for i, (word, tag) in enumerate(data.training_set.stream())]\n",
    "words = [word for i, (word, tag) in enumerate(data.training_set.stream())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FakeState = namedtuple('FakeState', 'name')\n",
    "\n",
    "class MFCTagger:\n",
    "    missing = FakeState(name = '<MISSING>')\n",
    "    \n",
    "    def __init__(self, table):\n",
    "        self.table = defaultdict(lambda: MFCTagger.missing)\n",
    "        self.table.update({word: FakeState(name=tag) for word, tag in table.items()})\n",
    "        \n",
    "    def viterbi(self, seq):\n",
    "        \"\"\"This method simplifies predictions by matching the Pomegranate viterbi() interface\"\"\"\n",
    "        return 0., list(enumerate([\"<start>\"] + [self.table[w] for w in seq] + [\"<end>\"]))\n",
    "    \n",
    "tags = [tag for i, (word, tag) in enumerate(data.training_set.stream())]\n",
    "words = [word for i, (word, tag) in enumerate(data.training_set.stream())]\n",
    "\n",
    "word_counts = pair_counts(words, tags)\n",
    "mfc_table = dict((word, max(tags.keys(), key=lambda key: tags[key])) for word, tags in word_counts.items())\n",
    "\n",
    "mfc_model = MFCTagger(mfc_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unknown(sequence):\n",
    "    \n",
    "    return [w if w in data.training_set.vocab else 'nan' for w in sequence]\n",
    "\n",
    "def simplify_decoding(X, model):\n",
    "    \n",
    "    _, state_path = model.viterbi(replace_unknown(X))\n",
    "    return [state[1].name for state in state_path[1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pos_tags(key):\n",
    "    print(f\"Sentence Key: {key}\")\n",
    "    print(\"Predicted labels:\\n----------------------------------\")\n",
    "    print(simplify_decoding(data.sentences[key].words, mfc_model))\n",
    "    print(\"Actual labels:\\n-------------------------------\")\n",
    "    print(data.sentences[key].tags)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-28144\n",
      "Predicted labels:\n",
      "----------------------------------\n",
      "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
      "Actual labels:\n",
      "-------------------------------\n",
      "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
      "\n",
      "Sentence Key: b100-23146\n",
      "Predicted labels:\n",
      "----------------------------------\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
      "Actual labels:\n",
      "-------------------------------\n",
      "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data.testing_set.keys[:2]:\n",
    "    predict_pos_tags(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model.viterbi call in simplify_decoding will return None if the HMM raises an error (for example, if a test sentence contains a word that is out of vocabulary for the training set). Any exception counts the full sentence as an error (which makes this a conservative estimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, Y, model):\n",
    "    \n",
    "    correct = total_predictions = 0\n",
    "    for observations, actual_tags in zip(X, Y):\n",
    "        try:\n",
    "            most_likely_tags = simplify_decoding(observations, model)\n",
    "            correct += sum( pred == tag for pred, tag in zip(most_likely_tags, actual_tags))\n",
    "        except:\n",
    "            pass\n",
    "        total_predictions += len(observations)\n",
    "    return correct / total_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy mfc_model: 95.72\n",
      "testing accuracy mfc_model: 93.01\n"
     ]
    }
   ],
   "source": [
    "mfc_training_acc = accuracy(data.training_set.X, data.training_set.Y, mfc_model)\n",
    "print(f\"training accuracy mfc_model: {mfc_training_acc*100 :.2f}\")\n",
    "\n",
    "mfc_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, mfc_model)\n",
    "print(f\"testing accuracy mfc_model: {mfc_testing_acc*100 :.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build HMM Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_counts(sequences):\n",
    "    return Counter(sequences)\n",
    "\n",
    "tags = [tag for i, (word, tag) in enumerate(data.training_set.stream())]\n",
    "tag_unigrams = unigram_counts(tags)\n",
    "\n",
    "def bigram_counts(sequences):\n",
    "    d = Counter(sequences)\n",
    "    return d\n",
    "\n",
    "tags = [tag for i, (word, tag) in enumerate(data.stream())]\n",
    "o = [(tags[i],tags[i+1]) for i in range(0,len(tags)-2,2)]\n",
    "tag_bigrams = bigram_counts(o)\n",
    "\n",
    "def starting_counts(sequences):\n",
    "    d = Counter(sequences)\n",
    "    return d\n",
    "\n",
    "start_tag = [i[0] for i in data.Y]\n",
    "tag_starts = starting_counts(start_tag)\n",
    "\n",
    "def ending_counts(sequences):\n",
    "    d = Counter(sequences)\n",
    "    return d\n",
    "\n",
    "end_tag = [i[len(i)-1] for i in data.Y]\n",
    "tag_ends = ending_counts(end_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_model = HiddenMarkovModel(name=\"base-hmm-tagger\")\n",
    "\n",
    "tags = [tag for i, (word, tag) in enumerate(data.stream())]\n",
    "words = [word for i, (word, tag) in enumerate(data.stream())]\n",
    "\n",
    "tags_count=unigram_counts(tags)\n",
    "tag_words_count=pair_counts(tags,words)\n",
    "\n",
    "starting_tag_list=[i[0] for i in data.Y]\n",
    "ending_tag_list=[i[-1] for i in data.Y]\n",
    "\n",
    "starting_tag_count=starting_counts(starting_tag_list)#the number of times a tag occured at the start\n",
    "ending_tag_count=ending_counts(ending_tag_list)      #the number of times a tag occured at the end\n",
    "\n",
    "\n",
    "\n",
    "to_pass_states = []\n",
    "for tag, words_dict in tag_words_count.items():\n",
    "    total = float(sum(words_dict.values()))\n",
    "    distribution = {word: count/total for word, count in words_dict.items()}\n",
    "    tag_emissions = DiscreteDistribution(distribution)\n",
    "    tag_state = State(tag_emissions, name=tag)\n",
    "    to_pass_states.append(tag_state)\n",
    "\n",
    "\n",
    "basic_model.add_states()    \n",
    "    \n",
    "\n",
    "start_prob={}\n",
    "\n",
    "for tag in tags:\n",
    "    start_prob[tag]=starting_tag_count[tag]/tags_count[tag]\n",
    "\n",
    "for tag_state in to_pass_states :\n",
    "    basic_model.add_transition(basic_model.start,tag_state,start_prob[tag_state.name])    \n",
    "\n",
    "end_prob={}\n",
    "\n",
    "for tag in tags:\n",
    "    end_prob[tag]=ending_tag_count[tag]/tags_count[tag]\n",
    "for tag_state in to_pass_states :\n",
    "    basic_model.add_transition(tag_state,basic_model.end,end_prob[tag_state.name])\n",
    "    \n",
    "\n",
    "\n",
    "transition_prob_pair={}\n",
    "\n",
    "for key in tag_bigrams.keys():\n",
    "    transition_prob_pair[key]=tag_bigrams.get(key)/tags_count[key[0]]\n",
    "for tag_state in to_pass_states :\n",
    "    for next_tag_state in to_pass_states :\n",
    "        basic_model.add_transition(tag_state,next_tag_state,transition_prob_pair[(tag_state.name,next_tag_state.name)])\n",
    "\n",
    "basic_model.bake()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-28144\n",
      "Predicted labels:\n",
      "----------------------------------\n",
      "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
      "Actual labels:\n",
      "-------------------------------\n",
      "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
      "\n",
      "Sentence Key: b100-23146\n",
      "Predicted labels:\n",
      "----------------------------------\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
      "Actual labels:\n",
      "-------------------------------\n",
      "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data.testing_set.keys[:2]:\n",
    "    predict_pos_tags(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy basic hmm model: 97.49\n",
      "testing accuracy basic hmm model: 96.09\n"
     ]
    }
   ],
   "source": [
    "hmm_training_acc = accuracy(data.training_set.X, data.training_set.Y, basic_model)\n",
    "print(f\"training accuracy basic hmm model: {hmm_training_acc*100 :.2f}\")\n",
    "\n",
    "hmm_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, basic_model)\n",
    "print(f\"testing accuracy basic hmm model: {hmm_testing_acc*100 :.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
